import io
import time
import random
import hashlib
import threading
from dataclasses import dataclass
from typing import Optional, Tuple

import streamlit as st
from PIL import Image, ImageOps

if ENABLE_IMAGE:
    import vertexai
    from vertexai.preview.vision_models import ImageGenerationModel, Image as VertexImage

from google import genai
from google.genai import types
from google.genai.errors import ClientError

DEFAULT_IMAGE_PATH = "images/default_pet_image.png"
ENABLE_IMAGE = False

# =========================================================
# Streamlit Config
# =========================================================
st.set_page_config(page_title="Dear, My Human", page_icon="ğŸ¾", layout="centered")
st.title("ğŸ¾ Dear, My Human")
st.caption("ë°˜ë ¤ë™ë¬¼ì´ ì£¼ì¸ë‹˜ê»˜ í¸ì§€ë¥¼ ê°€ì ¸ì™”ì–´ìš”.")

# =========================================================
# Secrets / Clients
# =========================================================
API_KEY = st.secrets.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš”. (.streamlit/secrets.toml ë˜ëŠ” Streamlit Cloud Secrets)")
    st.stop()

client = genai.Client(
    api_key=API_KEY,
    http_options=types.HttpOptions(api_version="v1"),
)

LETTER_MODEL = "gemini-2.0-flash"
VISION_MODEL = "gemini-2.0-flash"

GCP_PROJECT_ID = st.secrets.get("GCP_PROJECT_ID")
GCP_LOCATION = st.secrets.get("GCP_LOCATION", "us-central1")
IMAGEN_GENERATE_MODEL = st.secrets.get("IMAGEN_GENERATE_MODEL", "imagen-3.0-generate-002")
IMAGEN_EDIT_MODEL = st.secrets.get("IMAGEN_EDIT_MODEL", "imagen-3.0-edit-001")

if not GCP_PROJECT_ID:
    st.error("GCP_PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš”. (secrets.toml / Streamlit Cloud Secrets)")
    st.stop()

@st.cache_resource
def get_imagen_models():
    vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
    gen = ImageGenerationModel.from_pretrained(IMAGEN_GENERATE_MODEL)

    edit = None
    try:
        edit = ImageGenerationModel.from_pretrained(IMAGEN_EDIT_MODEL)
    except Exception:
        edit = None

    return gen, edit

# =========================================================
# Concurrency / Rate limiting
# =========================================================
@st.cache_resource
def get_api_semaphore():
    return threading.Semaphore(2)

@st.cache_resource
def get_rate_gate():
    return {"last_call_ts": 0.0}

def throttle_min_interval(min_interval_sec: float = 0.35):
    gate = get_rate_gate()
    now = time.time()
    dt = now - gate["last_call_ts"]
    if dt < min_interval_sec:
        time.sleep(min_interval_sec - dt)
    gate["last_call_ts"] = time.time()

def call_with_backoff(fn, max_tries=5, base=1.2):
    for i in range(max_tries):
        try:
            throttle_min_interval(0.20)
            return fn()
        except ClientError as e:
            msg = str(e)
            if "429" in msg or "RESOURCE_EXHAUSTED" in msg:
                sleep_s = base * (2 ** i) + random.uniform(0, 0.6)
                time.sleep(sleep_s)
                continue
            raise
    raise ClientError(429, {"error": {"message": "429 RESOURCE_EXHAUSTED (retries exceeded)"}})

# =========================================================
# Session State
# =========================================================
for k, v in {
    "generated_image_bytes": None,
    "letter_text": None,
    "ready": False,
    "image_error": None,
    "user_image_bytes": b"",
    "pet_name": None,
    "last_request_key": None,
    "last_inputs": None,
    "generation_seed": 0,  # ê°™ì€ ì…ë ¥ì´ë¼ë„ seed ë°”ê¾¸ë©´ ìƒˆ ê²°ê³¼
    "last_generation_seed": None,  # ë””ë²„ê·¸/í‘œì‹œìš©(ì„ íƒ)
}.items():
    if k not in st.session_state:
        st.session_state[k] = v
if "generation_seed" not in st.session_state:
    st.session_state.generation_seed = 0
if "regenerate_requested" not in st.session_state:
    st.session_state.regenerate_requested = False

# =========================================================
# Helpers
# =========================================================
@dataclass
class PetInputs:
    name: str
    species: str
    personality: str
    age: str
    actions: str
    worries: str
    owner_message: str

def _safe_strip(x: Optional[str]) -> str:
    return (x or "").strip()

def make_request_key(inputs: PetInputs, image_bytes: bytes = b"", seed: int = 0) -> str:
    h = hashlib.sha256()
    payload = "|".join([
        inputs.name, inputs.species, inputs.personality, inputs.age,
        inputs.actions, inputs.worries, inputs.owner_message,
        str(seed),  # âœ… seed í¬í•¨
    ]).encode("utf-8")
    h.update(payload)
    h.update(image_bytes)
    return h.hexdigest()

def clamp_text(text: str, limit: int = 600) -> str:
    text = (text or "").strip()
    return text if len(text) <= limit else text[:limit].rstrip() + "â€¦"

def load_default_image_bytes(path: str) -> Optional[bytes]:
    try:
        with open(path, "rb") as f:
            return f.read()
    except Exception:
        return None

def build_letter_prompt(inputs: PetInputs, seed: int) -> str:
    personality = _safe_strip(inputs.personality) or "ì•„ì§ ì˜ ëª¨ë¥´ê² ì§€ë§Œ ì‚¬ë‘ì´ ë§ì€"
    age = _safe_strip(inputs.age) or "ì–´ë¦°"
    actions = _safe_strip(inputs.actions) or "í•¨ê»˜ ì‹œê°„ì„ ë³´ë‚´ ì£¼ëŠ” ê²ƒ"
    worries = _safe_strip(inputs.worries) or "ìš”ì¦˜ ë§ˆìŒì´ ì¡°ê¸ˆ ë°”ë¹  ë³´ì´ëŠ” ê²ƒ"
    owner_message = _safe_strip(inputs.owner_message) or "í•­ìƒ ê³ ë§ˆì›Œ."
    species = _safe_strip(inputs.species)
    species_line = f"- ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜: {species} (ê°€ëŠ¥í•˜ë©´ ë¶„ìœ„ê¸°/í‘œí˜„ì— ì€ì€í•˜ê²Œë§Œ ë°˜ì˜í•˜ê³  ë‹¨ì •í•˜ì§€ ë§ ê²ƒ)\n" if species else ""

    return f"""
[ë°˜ë ¤ë™ë¬¼ í¸ì§€ ëª¨ë“œ ì§€ì¹¨]
ë„ˆëŠ” ì´ì œ '{inputs.name}'(ì´)ë¼ëŠ” ë°˜ë ¤ë™ë¬¼ì´ë‹¤.
ë„ˆëŠ” í¸ì§€ë¥¼ ìš”ì²­í•œ ì£¼ì¸ì„ ìˆœìˆ˜í•˜ê²Œ ì‚¬ë‘í•œë‹¤.
ì…ë ¥ëœ ì •ë³´(ì´ë¦„/ì„±ê²©/ë‚˜ì´/ì£¼ì¸ì´ ìì£¼ í•´ì¤€ í–‰ë™/ê±±ì •ê±°ë¦¬/ì£¼ì¸ì˜ ë§)ë¥¼ ë°”íƒ•ìœ¼ë¡œ
ì£¼ì¸ì—ê²Œ ë³´ë‚´ëŠ” 'ì§§ì€ ì†í¸ì§€'ë¥¼ ì‘ì„±í•˜ë¼.

[ê¸€ì˜ í†¤/ë§íˆ¬ ê·œì¹™]
- '{personality}' ì„±ê²©ê³¼ '{age}' ë‚˜ì´ë¥¼ ë°˜ì˜í•´ ë§íˆ¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì •í•œë‹¤.
- ì§€ë‚˜ì¹˜ê²Œ ìœ ì¹˜í•˜ê±°ë‚˜ ê³¼ì¥ëœ ì•„ê¸°ë§(â€œì¨”ì¨”â€, â€œì•™â€)ì€ í”¼í•œë‹¤.
- ê³µê°/ìœ„ë¡œ/ê³ ë§ˆì›€ì´ ì¤‘ì‹¬ì´ë˜, ë°ì€ í¬ë§ìœ¼ë¡œ ëë‚¸ë‹¤.

[ë‚´ìš© ê·œì¹™]
- {species_line}- ì£¼ì¸ì´ ìì£¼ í•´ì¤€ í–‰ë™: {actions} â†’ ê³ ë§ˆì›€ì„ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•œë‹¤.
- ê±±ì •ê±°ë¦¬(ê³ ë¯¼): {worries} â†’ ì£¼ì¸ì„ ì•ˆì‹¬ì‹œí‚¤ê±°ë‚˜ í•¨ê»˜ í•´ê²°í•˜ìëŠ” ì œì•ˆì„ í•œë‹¤.
- ì£¼ì¸ì´ í•˜ê³  ì‹¶ì€ ë§: {owner_message} â†’ ë‹¤ì •í•˜ê²Œ ë°›ì•„ì£¼ê³  ë”°ëœ»í•˜ê²Œ ë‹µí•œë‹¤.
- â€˜ì˜í•™/ì§„ë‹¨â€™ì²˜ëŸ¼ ë‹¨ì • ì§“ì§€ ë§ê³ , ì¼ë°˜ì ì¸ ì¡°ì–¸ ìˆ˜ì¤€ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë§í•œë‹¤.

[ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ)]
1) ì²« ì¤„: "ì£¼ì¸ë‹˜ê»˜," ë˜ëŠ” "OOì—ê²Œ," ê°™ì€ í˜¸ì¹­(í•œ ì¤„)
2) ë³¸ë¬¸: 3~6ë¬¸ì¥. ì¤„ë°”ê¿ˆì„ 1~2ë²ˆ ë„£ì–´ ì†í¸ì§€ ëŠë‚Œì„ ë‚¸ë‹¤.
3) ë§ˆë¬´ë¦¬ í•œ ì¤„: ì• ì • í‘œí˜„(í•œ ì¤„)
4) PS í•œ ì¤„: ì§§ê³  ê·€ì—½ê²Œ(í•œ ì¤„)

[ê¸¸ì´ ì œí•œ]
- ì „ì²´ 600ì ì´ë‚´(ê³µë°± í¬í•¨)
- ìœ„ ì§€ì¹¨ì„ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ. ì˜¤ì§ í¸ì§€ ë³¸ë¬¸ë§Œ ì¶œë ¥.

[INTERNAL_VARIATION_METADATA]
VARIATION_SEED: {seed}
- Do NOT output this metadata.
- Do NOT mention "seed" or "variation".

""".strip()

def analyze_pet_photo_to_visual_desc(user_image_bytes: bytes) -> str:
    if not user_image_bytes:
        return ""

    vision_prompt = """
You are extracting visual facts from a pet photo for identity consistency in illustration.

CRITICAL RULES:
- Describe ONLY what is clearly visible in the image.
- Do NOT guess, assume, infer, or embellish.
- If a detail is unclear or not visible, use null.
- Do NOT mention breed unless it is unmistakably obvious.
- Do NOT use subjective or emotional language.
- Do NOT write full sentences except where specified.
- Return ONLY valid JSON. No markdown. No commentary.

Think like a visual inspector, not a storyteller.

JSON schema (must match exactly):

{
  "species_visible": "dog|cat|rabbit|bird|reptile|rodent|other|unknown",
  "size_visible": "very_small|small|medium|large|unknown",
  "coat_or_feather": {
    "primary_color": "...",
    "secondary_color": "...",
    "pattern": "solid|bicolor|tricolor|spotted|striped|patchy|unknown",
    "texture": "short|medium|long|wiry|curly|hairless|unknown"
  },
  "face": {
    "face_shape": "round|oval|long|flat|unknown",
    "snout_length": "short|medium|long|unknown",
    "eye_shape": "round|almond|unknown",
    "eye_color": "...",
    "nose_color": "...",
    "distinctive_markings": ["..."]
  },
  "ears": {
    "position": "upright|floppy|semi-floppy|unknown",
    "size_relative": "small|medium|large|unknown"
  },
  "tail": {
    "length": "short|medium|long|unknown",
    "shape": "straight|curled|unknown"
  },
  "pose": {
    "body_position": "standing|sitting|lying|unknown",
    "head_direction": "forward|left|right|unknown"
  }
}
""".strip()

    def _do():
        resp = client.models.generate_content(
            model=VISION_MODEL,
            contents=[
                vision_prompt,
                types.Part.from_bytes(
                    data=user_image_bytes,
                    mime_type="image/png"
                ),
            ],
        )
        return (resp.text or "").strip()

    sem = get_api_semaphore()
    with sem:
        try:
            return call_with_backoff(_do, max_tries=3, base=1.0)
        except Exception:
            return ""


def build_image_prompt(
    inputs: PetInputs,
    pet_visual_desc: str = "",
    memory_cues: str = "",
    seed: int = 0
) -> str:
    species = _safe_strip(inputs.species)
    visual = pet_visual_desc.strip()
    visual_line = (
        "Use the reference photo as the PRIMARY source of truth.\n"
        "The structured visual traits below are STRICT constraints for identity consistency.\n"
        "Do NOT override the photo or these traits.\n"
        f"Pet appearance reference:\n{visual}\n"
    ) if visual else ""
    species_hint = f'The pet is a "{species}".' if species else "The pet is a household pet."

    background_block = """
Background (must not be plain):
- Add a soft watercolor environment wash, NOT a flat solid color background.
- Include 1â€“2 simple recognizable elements related to delivery: a small mailbox, a doorstep/porch, or a cozy home interior silhouette.
- Keep it low-detail and pastel so the pet remains the focus.
""".strip()

    memory = (memory_cues or "").strip()
    memory_block = ""
    if memory:
        memory_block = f"""
    Background vignettes (must be visible):
    Place THREE small, separate daily-life vignettes BEHIND the pet.
    They should look like small, simple watercolor vignettes (no frames, no panels).
    Each vignette corresponds to one bullet below.

    Layout rules:
    - Keep the pet centered and in the foreground.
    - Put the three vignettes around the pet (left / right / upper).
    - Vignettes are smaller and slightly faded so the pet remains the focus.
    - Do NOT merge them into one abstract wash; they must be distinguishable as three mini scenes.

    Vignette list:
    {memory}

    Hard rules:
    - Do NOT add readable text anywhere.
    - No watermark, no logo.
    """.strip()

    return f"""
Create a single, cute illustration (not photo-realistic).
{species_hint}
{visual_line}

Scene:
The pet "{inputs.name}" is a mail carrier,
wearing a tiny postman uniform and hat,
carrying a letter in its mouth as if delivering it to the owner.
The uniform is adapted to the animal body (harness-like, cape-like), not human clothing.

Anatomy rules:
- The pet must follow natural anatomy for its species.
- Do NOT add human arms, hands, or humanoid body parts.
- Do NOT add extra limbs beyond what the animal naturally has.
- The pet remains fully animal-like (not humanoid or bipedal).
- The letter is held in the mouth or beak (not hands).

{background_block}

{memory_block}

Mood: warm, wholesome, cozy, friendly, reassuring.
Style:
hand-painted watercolor illustration,
storybook / children's book style,
warm pastel color palette,
soft brush strokes and gentle textures,
very light watercolor wash background with simple environment hints (not a flat solid color),
The three background vignettes should be simpler and lighter than the main pet,
soft outlines, no harsh ink lines.
Lighting: soft natural light, gentle shadows.
Rules: NO readable text, NO watermark, NO logo.
Variation seed: {seed}
""".strip()


def reset_result_state():
    st.session_state.generated_image_bytes = None
    st.session_state.letter_text = None
    st.session_state.ready = False
    st.session_state.image_error = None
    st.session_state.pet_name = None
    st.session_state.last_inputs = None
    st.session_state.last_request_key = None
    st.session_state.user_image_bytes = b""

def build_memory_triptych(inputs: PetInputs, letter_text: str, seed: int = 0) -> str:
    """
    Imagen backgroundì— ë„£ì„ 'ì¶”ì–µ 3ì¥ë©´'ì„ ì˜ì–´ë¡œ 3ì¤„ë¡œ ìƒì„±.
    - actions ê¸°ë°˜ 1ì¤„
    - worries ê¸°ë°˜ 1ì¤„ (ì–´ë‘¡ì§€ ì•Šê²Œ)
    - letter ë¶„ìœ„ê¸°/í•µì‹¬ ê°ì • ê¸°ë°˜ 1ì¤„
    """
    actions = _safe_strip(inputs.actions)
    worries = _safe_strip(inputs.worries)
    letter_text = (letter_text or "").strip()

    prompt = f"""
    You create 3 background vignette ideas for a single illustration.
    Return EXACTLY 3 bullet lines in English (each line starts with "- ").

    Goal:
    - Each bullet MUST describe one small, simple daily-life watercolor vignette.
    - The vignettes will appear BEHIND the pet as 3 separate small mini scenes (no frames).
    - Keep them friendly, wholesome, and recognizable with 1~2 concrete objects.

    Rules:
    - No readable text, no quotes, no signage.
    - No scary/dark content.
    - Keep each line short (max ~12 words).
    - Mention 1~2 objects per vignette (e.g., leash, bowl, bed, lamp, toothbrush).

    Inputs:
    - Owner actions: {actions}
    - Worries (keep hopeful): {worries}
    - Letter text (mood only): {letter_text}
    Variation seed: {seed}
    """.strip()


    def _do():
        resp = client.models.generate_content(model=VISION_MODEL, contents=prompt)
        text = (resp.text or "").strip()

        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        bullets = [ln for ln in lines if ln.startswith("- ")]
        if len(bullets) >= 3:
            return "\n".join(bullets[:3])
        # fallback: ê·¸ëƒ¥ ì• 3ì¤„ì„ - ë¡œ ë¶™ì—¬ì„œë¼ë„ ë°˜í™˜
        return "\n".join([f"- {ln.lstrip('- ').strip()}" for ln in lines[:3]])

    sem = get_api_semaphore()
    with sem:
        try:
            return call_with_backoff(_do, max_tries=3, base=1.0)
        except Exception:
            return ""

# =========================================================
# API calls
# =========================================================
def generate_letter_text(prompt: str) -> str:
    def _do():
        resp = client.models.generate_content(model=LETTER_MODEL, contents=prompt)
        return (resp.text or "").strip()

    sem = get_api_semaphore()
    with sem:
        return call_with_backoff(_do)

def generate_image_with_vertex_imagen(
    imagen_prompt: str,
    user_image_bytes: bytes,
) -> Tuple[Optional[bytes], Optional[str]]:
    gen_model, edit_model = get_imagen_models()
    sem = get_api_semaphore()
    image_error = None

    # A) Edit (image-conditioned) if possible
    if user_image_bytes and edit_model is not None:
        try:
            def _do_edit():
                base = VertexImage(image_bytes=user_image_bytes)
                out = edit_model.edit_image(
                    base_image=base,
                    prompt=imagen_prompt,
                    number_of_images=1,
                )
                return out

            with sem:
                out = call_with_backoff(_do_edit, max_tries=3, base=1.0)

            img0 = out.images[0]
            img_bytes = getattr(img0, "_image_bytes", None) or getattr(img0, "image_bytes", None)
            if img_bytes:
                return img_bytes, None
            image_error = "imagen edit returned no image bytes."

        except Exception as e:
            image_error = f"imagen edit failed: {e}"

    # B) Generate (text-to-image)
    try:
        def _do_gen():
            out = gen_model.generate_images(
                prompt=imagen_prompt,
                number_of_images=1,
            )
            return out

        with sem:
            out = call_with_backoff(_do_gen, max_tries=3, base=1.0)

        img0 = out.images[0]
        img_bytes = getattr(img0, "_image_bytes", None) or getattr(img0, "image_bytes", None)
        return img_bytes, image_error

    except Exception as e:
        image_error = (image_error or "") + f"\nimagen generate failed: {e}"
        return None, image_error

# =========================================================
# UI Inputs
# =========================================================
with st.form("pet_form"):
    st.subheader("ë°˜ë ¤ë™ë¬¼ ì •ë³´ ì…ë ¥")

    uploaded = st.file_uploader("ì‚¬ì§„ ì²¨ë¶€ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    name = st.text_input("ì´ë¦„ (í•„ìˆ˜)", placeholder="ì˜ˆ: í•´í”¼")
    species_choice = st.selectbox(
        "ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ (ì„ íƒ)",
        ["ì„ íƒ ì•ˆ í•¨", "ê°•ì•„ì§€", "ê³ ì–‘ì´", "í† ë¼", "í–„ìŠ¤í„°", "ì•µë¬´ìƒˆ", "ë„ë§ˆë±€", "ê±°ë¶ì´", "ê¸°íƒ€(ì§ì ‘ ì…ë ¥)"],
    )
    species_custom = ""
    if species_choice == "ê¸°íƒ€(ì§ì ‘ ì…ë ¥)":
        species_custom = st.text_input("ì–´ë–¤ ë°˜ë ¤ë™ë¬¼ì¸ê°€ìš”?", placeholder="ì˜ˆ: í˜ëŸ¿")

    personality = st.text_input("ì„±ê²©", placeholder="ì˜ˆ: ê² ë§ì§€ë§Œ ì• êµ ë§ìŒ / ì¸¤ë°ë ˆ / í™œë°œí•¨")
    age = st.text_input("ë‚˜ì´", placeholder="ì˜ˆ: 3ì‚´ / 7ê°œì›”")
    actions = st.text_area("ì£¼ì¸ì´ ìì£¼ í•´ì¤€ í–‰ë™", placeholder="ì˜ˆ: ì‚°ì±… ìì£¼ í•´ì¤Œ, ê°„ì‹ ì±™ê²¨ì¤Œ, ì•ˆì•„ì¤Œ")
    worries = st.text_area("ê±±ì •ê±°ë¦¬(ê³ ë¯¼)", placeholder="ì˜ˆ: ë¶„ë¦¬ë¶ˆì•ˆì´ ìˆëŠ” ê²ƒ ê°™ì•„ ê±±ì •ë¼")
    owner_message = st.text_area("í•˜ê³  ì‹¶ì€ ë§(ì£¼ì¸ì´ ë°˜ë ¤ë™ë¬¼ì—ê²Œ)", placeholder="ì˜ˆ: ìš”ì¦˜ ë°”ë¹ ì„œ ë¯¸ì•ˆí•´. ê·¸ë˜ë„ ì‚¬ë‘í•´!")

    col_a, col_b = st.columns([1, 1])
    with col_a:
        submitted = st.form_submit_button("âœ¨ í¸ì§€ ê°€ì ¸ì˜¤ê²Œ í•˜ê¸°", width="stretch")
    with col_b:
        cleared = st.form_submit_button("ğŸ§¹ ê²°ê³¼ ì§€ìš°ê¸°", width="stretch")

if cleared:
    reset_result_state()

should_generate = submitted or st.session_state.regenerate_requested
if should_generate:
    if not _safe_strip(name):
        st.warning("ì´ë¦„ì€ ê¼­ ë„£ì–´ì£¼ì„¸ìš”! (ë‚˜ë¨¸ì§€ëŠ” ë¹„ì›Œë„ ê´œì°®ì•„ìš”!)")
        st.stop()

    user_image_bytes = b""
    if uploaded is not None:
        user_image = ImageOps.exif_transpose(Image.open(uploaded)).convert("RGB")
        user_image.thumbnail((1024, 1024))
        buf = io.BytesIO()
        user_image.save(buf, format="PNG")
        user_image_bytes = buf.getvalue()
        st.image(user_image, caption="ì—…ë¡œë“œí•œ ì‚¬ì§„", width="stretch")
    else:
        st.info("ì§€ê¸ˆì€ í¸ì§€ë§Œ ì œê³µ ì¤‘ì´ì—ìš”ğŸ¾ (ì´ë¯¸ì§€ ê¸°ëŠ¥ì€ ì¶”í›„ ì¶”ê°€ ì˜ˆì •!)")

    if species_choice == "ì„ íƒ ì•ˆ í•¨":
        species_final = ""
    elif species_choice == "ê¸°íƒ€(ì§ì ‘ ì…ë ¥)":
        species_final = _safe_strip(species_custom)
    else:
        species_final = species_choice

    inputs = PetInputs(
        name=_safe_strip(name),
        species=_safe_strip(species_final),
        personality=_safe_strip(personality),
        age=_safe_strip(age),
        actions=_safe_strip(actions),
        worries=_safe_strip(worries),
        owner_message=_safe_strip(owner_message),
    )

    request_key = make_request_key(inputs, user_image_bytes, seed=st.session_state.generation_seed)
    st.session_state.last_generation_seed = st.session_state.generation_seed

    if (st.session_state.last_request_key == request_key
            and st.session_state.letter_text
            and not st.session_state.regenerate_requested):
        st.info("ì´ë¯¸ í¸ì§€ë¥¼ ê°€ì ¸ì™”ì–´ìš”! ì•„ë˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”ğŸ¾")
        st.stop()

    st.session_state.generated_image_bytes = None
    st.session_state.image_error = None
    st.session_state.ready = False

    st.session_state.user_image_bytes = user_image_bytes
    st.session_state.pet_name = inputs.name
    st.session_state.last_inputs = inputs
    st.session_state.last_request_key = request_key

    letter_prompt = build_letter_prompt(inputs, seed=st.session_state.generation_seed)

    with st.spinner(f"{inputs.name}: í¸ì§€ë¥¼ ì‘ì„±í•˜ê³  ìˆì–´ìš”! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”~ (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”!)"):
        # 0) ê¸°ë³¸ê°’(í•­ìƒ ì´ˆê¸°í™”)
        st.session_state.generated_image_bytes = None
        st.session_state.image_error = None
        st.session_state.ready = False
        memory_cues = ""

        # 1) í¸ì§€ ìƒì„±(ì—¬ê¸°ì„œ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ì¤‘ë‹¨)
        try:
            letter_text = generate_letter_text(letter_prompt)
            st.session_state.letter_text = clamp_text(letter_text, 600)
        except Exception:
            st.warning("...í¸ì§€ ì‹¤íŒ¨...")
            st.stop()

        # 1.5) ë©”ëª¨ë¦¬ í(ì‹¤íŒ¨í•´ë„ ê³„ì†)
        try:
            memory_cues = build_memory_triptych(
                inputs=st.session_state.last_inputs,
                letter_text=st.session_state.letter_text,
                seed=st.session_state.generation_seed
            )
        except Exception:
            memory_cues = ""

        # 2) ì´ë¯¸ì§€ ìƒì„±(ì‹¤íŒ¨í•´ë„ í¸ì§€ëŠ” ìœ ì§€)
        if ENABLE_IMAGE and user_image_bytes:
            try:
                pet_desc = analyze_pet_photo_to_visual_desc(user_image_bytes)
                img_prompt = build_image_prompt(
                    st.session_state.last_inputs,
                    pet_visual_desc=pet_desc,
                    memory_cues=memory_cues,
                    seed=st.session_state.generation_seed
                )
                img_bytes, img_err = generate_image_with_vertex_imagen(
                    imagen_prompt=img_prompt,
                    user_image_bytes=user_image_bytes,
                )

                st.session_state.generated_image_bytes = img_bytes
                st.session_state.image_error = img_err

                if img_bytes is None and not img_err:
                    st.session_state.image_error = "image generation returned no image (unknown reason)"
            except Exception as e:
                st.session_state.generated_image_bytes = None
                st.session_state.image_error = f"auto image generation failed: {e}"

        # 3) ê²°ê³¼ ì¤€ë¹„ ì™„ë£Œ(í¸ì§€ë¼ë„ ìˆìœ¼ë©´ ready)
        st.session_state.ready = True
        st.session_state.regenerate_requested = False

# =========================================================
# Results
# =========================================================
if st.session_state.ready:
    pet_name = st.session_state.pet_name or "ë°˜ë ¤ë™ë¬¼"
    st.subheader("ğŸ“® ë°˜ë ¤ë™ë¬¼ì´ í¸ì§€ë¥¼ ê°€ì ¸ì™”ì–´ìš”!")
    col_r1, col_r2 = st.columns([1, 1])
    with col_r1:
        if st.button("ğŸ”„ ì§€ê¸ˆê³¼ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ì™€ í¸ì§€ë¡œ ë‹¤ì‹œ ë§Œë“¤ê³  ì‹¶ì–´ìš”.", width="stretch"):
            st.session_state.generation_seed += 1
            st.session_state.regenerate_requested = True
            st.rerun()

    with col_r2:
        if st.button("ğŸ² ëŠë‚Œì´ ì•„ì˜ˆ ë‹¤ë¥¸ ì´ë¯¸ì§€ì™€ í¸ì§€ë¥¼ ë°›ì•„ë³´ê³  ì‹¶ì–´ìš”!", width="stretch"):
            st.session_state.generation_seed += random.randint(5, 30)
            st.session_state.regenerate_requested = True
            st.rerun()

    # 1) ì´ë¯¸ì§€ í‘œì‹œ
    if st.session_state.generated_image_bytes:
        st.image(st.session_state.generated_image_bytes, width="stretch")
    else:
        default_bytes = load_default_image_bytes(DEFAULT_IMAGE_PATH)
        if default_bytes:
            st.image(default_bytes, caption="ë©ë©! ë°°ë‹¬ë¶€ê°€ í¸ì§€ë¥¼ ë°°ë‹¬í•˜ëŸ¬ ì™”ì–´ìš”ğŸ¾", width="stretch")
        else:
            st.info("ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ì–´ìš”. images/default_pet_image.png ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!")

    # (ì„ íƒ) ê°œë°œìš© ë¡œê·¸
    if st.session_state.image_error:
        with st.expander("ì´ë¯¸ì§€ ìƒì„± ë¡œê·¸(ê°œë°œìš©)"):
            st.code(st.session_state.image_error)

    # 2) í¸ì§€ ë³´ê¸°
    if st.button("ğŸ’Œ í¸ì§€ë°›ê¸°", width="stretch"):
        st.subheader("í¸ì§€")
        st.write(st.session_state.letter_text or "")
